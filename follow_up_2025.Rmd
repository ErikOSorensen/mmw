---
title: "Follow-up study 2025"
author: "Erik Ø. Sørensen"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(targets)
library(stringr)
library(tidyverse)
library(gt)
library(modelsummary)
library(fixest)
library(marginaleffects)
library(patchwork)
library(labelled)
```


# The winning margin

The reference case we used for power calculations was columns 1 and 4 of
Table~3. 

We can try to calculate something similar using the follow-up data,
and see if there are any treatment differences.


```{r winning margin 2025, message=FALSE, warning=FALSE, include=FALSE}
tar_load(role_of_winning_margin_2025)
cm <- c("winning_margin" = "Winning Margin",
        "winning_margin:treatmentfattention" = "W.M. X Attention",
        "winning_margin:treatmentfshow_distribution" = "W.M. X Show dist.",
        "treatmentfattention"="Attention treatment",
        "treatmentfshow_distribution" = "Show dist. treatment",
        "x2" = "Performance Winner",
        "(Intercept)"="Constant"
        )
tab3 <- role_of_winning_margin_2025$regressions |>
  modelsummary(coef_map=cm,
               stars = c('*' = .1, '**' = .05, '***'=.01),
                                   gof_map = c("nobs", "r.squared"),
                                   output = "gt",
               add_rows = role_of_winning_margin_2025$extra_rows) |>
  tab_spanner(label="All to Winner", columns=2:5) |>
  tab_spanner(label="Share to Winner", columns=6:9)
tab3
tab3 |> gtsave(here::here("tables","P2025_winning_margin.tex"))
```

In columns 3,4 and 7,8, there are also other controls (same as those used
in the paper).


- We see that the size of the coefficient on winning margin is a bit larger than in the 2018 experiment (in which it was 0.006).
- In the "attention" treatment, the coefficient is $0.013-0.007 = 0.006$, exactly that of the 2018 experiment (if anything,
the winning margin is *less* important in the attention check treatment). 
- There are no significant treatment differences, and the treatment differences are small.
- The levels (constant terms in columns 1 and 5) are not far from those in the paper based on the 2018 numbers.


Are there differences within the "show distribution" treatment depending on where the
total production falls? I split the performance by median. Now there are three natural
groups: 1) Both winner and loser are below median, 2) Winner is above median, loser belows, 3) Both winner and loser are below 
median.
```{r}
tar_load(by_place_in_distribution)
fm <- c("winning_margin" = "Winning Margin",
        "republican" = "Republican",
        "college" ="College",
        "female" = "Female",
        "above_median_age"="Above median age",
        "(Intercept)"="Constant"
        )
ntab <- by_place_in_distribution |>
  modelsummary(coef_map=fm,
               stars = c('*' = .1, '**' = .05, '***'=.01),
                                   gof_map = c("nobs", "r.squared"),
                                   output = "gt") |>
  tab_spanner(label="All to winner", columns=2:3, id=1) |>
  tab_spanner(label="Share to winner", columns=4:5, id=2) |>
  tab_spanner(label="All to winner", columns=6:7, id=3) |>
  tab_spanner(label="Share to winner", columns=8:9, id=4) |>
  tab_spanner(label="All to winner", columns=10:11, id=5) |>
  tab_spanner(label="Share to winner", columns=12:13, id=6) |>
  tab_spanner(label="Both below median", columns=2:5) |>
  tab_spanner(label="Winner at or above median", columns=6:9) |>
  tab_spanner(label="Both at or above median", columns=10:13) 
ntab 
ntab |> gtsave(here::here("tables","P2025_ntab.tex"))
```

# Distribution of worker performance and winner margin

```{r distributions in 2025, echo=FALSE}
tar_load(distributions_performance_and_margin)
X <- distributions_performance_and_margin
distributions_2025 <-X$a + X$b + plot_annotation(tag_levels = 'a')
distributions_2025
ggsave(here::here("graphs","P2025_distributions.pdf"), width=16, height = 10, units="cm")
```


# Attention check

We asked for four numbers in the attention check: For both in a worker pair,
what was the number of problems solved, and what was pre-distribution earnings. 
Participants had to put in *some* numbers for the rest of the screen to appear,
but there was no testing that the numbers they entered were correct.

How accurate are the answers? 

```{r echo=FALSE, message=FALSE, warning=FALSE}
tar_load(mmw2025)
mmw2025 |> filter(treatment=="attention") |>
  mutate(x1_correct = x1==ax1,
         x2_correct = x2==ax2,
         e1_correct = abs(e1-ae1)<0.0001,
         e2_correct = abs(e2-ae2)<0.0001) |>
  summarize(mean_x1_correct = mean(x1_correct),
            mean_x2_correct = mean(x2_correct),
            mean_e1_correct = mean(e1_correct),
            mean_e2_correct = mean(e2_correct)) |>
  gt() |> fmt_number(decimals=3)
```
- I think we can conclude that participants mostly *did* manage to enter
the correct number; participants did pay attention. 



# Association Between Giving All to the Winner and General Attitudes

Note that "Gold Medalist" and "Superstar" have been reverse coded.
```{r}
tar_load(ass_giving_all_attitudes_2025)
em <- c("all_to_winner" = "All to winner",
        "republican" = "Republican",
        "college" ="College",
        "female" = "Female",
        "above_median_age"="Above median age",
        "(Intercept)"="Constant"
)

t4_2025 <- ass_giving_all_attitudes_2025 |>
   modelsummary(coef_map=em,
               stars = c('*' = .1, '**' = .05, '***'=.01),
                                   gof_map = c("nobs", "r.squared"),
                                   output = "gt" ) |>
  tab_spanner(label="Gold medalist", columns=2:4) |>
  tab_spanner(label="Superstar", columns=5:7) |>
  tab_spanner(label="Decrease tax on top 1\\%", columns=8:10)
t4_2025
t4_2025 |> gtsave(here::here("tables","P2025_attitudes.tex"))
```


# Using the data on classification


```{r Shares of classifications, echo=FALSE}
tar_load(classified_motivations)
classified_motivations |> 
  group_by(predicted_label) |>
  summarize(count=n(),
            fraction = count/nrow(classified_motivations)) |>
  arrange(-fraction) |> gt() |> fmt_number(decimals=3, column=3)
tdf <-classified_motivations |>
  mutate(label = case_when(
    predicted_label == "compensate" ~ "Other",
    predicted_label == "egalitarian" ~ "Egalitarian",
    predicted_label == "fairness" ~ "Fairness",
    predicted_label == "incentives" ~ "Other",
    predicted_label == "libertarian" ~ "Libertarian",
    predicted_label == "logic" ~ "Other",
    predicted_label == "meritocrat - margin does not matter" ~ "Meritocrat - Margin Not Mentioned",
    predicted_label == "meritocrat - margin matters" ~ "Meritocrat - Margin Mentioned",
    predicted_label == "misunderstand" ~ "Other",
    predicted_label == "no reason" ~ "Other")) |>
  group_by(label) |>
  summarise(fraction= n()/nrow(classified_motivations), .groups = "drop") |>
  mutate(labelf = factor(label, levels=rev(c("Meritocrat - Margin Not Mentioned", 
                                          "Meritocrat - Margin Mentioned",
                                          "Libertarian", 
                                          "Egalitarian",
                                          "Fairness",
                                          "Other"))))
tdf |>
  ggplot(aes(x=labelf, y=fraction)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(x = "Classification (GPT)",
       y = "Fraction") +
  theme_minimal()
ggsave("graphs/P2025_classifications.pdf", width=16, height = 10, units = "cm")
tdf |> dplyr::select(c("labelf","fraction")) |> arrange(-fraction) |> gt() |> fmt_number(decimals = 3)
```

Is it the case that the classifications are informative about distribution?

```{r Classifications and decisions, echo=FALSE}
tar_load(mmw2025)
cdta <- mmw2025 |> left_join(classified_motivations) |>
  mutate( all_to_winner = as.numeric(y2==e2),
          almost_equality = as.numeric(abs(y2 - e2/2)<0.1),
          lib_nomargin = as.numeric( predicted_label %in% c("libertarian","meritocrat - margin does not matter")),
          margin_matters = as.numeric(predicted_label %in% c("meritocrat - margin matters"))) 
cdta |> lm(all_to_winner ~ lib_nomargin, data=_) |> summary()
cdta |> lm(almost_equality ~ margin_matters, data=_) |> summary()

```

